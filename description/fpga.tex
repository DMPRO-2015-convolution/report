\section{FPGA}
\begin{figure}
    \centering
    \includegraphics{img/FpgaOverview}
    \caption{FPGA Overview}
    \label{fig:FpgaOverview}
\end{figure}

On the FPGA we must handle an incoming video stream and the configuration data arriving from the MCU before we perform the actual convolution and output the final video stream. In addition, some of the different components run at different clock speeds, thus we need to introduce queues to synchronize data on the boundaries between clock domains.

In Figure \ref{fig:FpgaOverview}, the top components on the FPGA are depicted.

\subsection{EBI}
As EBI is asynchronous, the incoming data for the FPGA must be synchronized to the processor clock domain before being used by clocked logic in the FPGA.
This is done by sending the data through a first-in first-out (FIFO) queue immediately after arrival.

After being synchronized, the EBI manager checks the addresses to determine what action to perform. In some cases, the data is resized from 16 to 24 bits and forwarded to the processor. In other cases, the data sets a control bit in the EBI manager which turns on EFM mode for the FPGA.

In EFM mode, EBI is routed to one of the memory chips to allow the MCU to read and write data and the HDMI output module is locked to the very same chip.
This allows the MCU to paint user interfaces on the screen so that the system can be controlled through buttons.
Configuration may include loading a new bit file onto the FPGA or setting up a different kernel for the processor.

\subsection{Memory}
The memory manager handles reading and writing to memory, and swapping the chips used as a double buffer when a frame is finished.
This includes calculating what addresses to place the arriving data at and what data to read.

In addition, the chip enable (or write enable) signal for the memory chips have to be pulsed in order to save data, which requires write cycle management.
This consists of a set-up phase and a write phase, giving a duty cycle of \unit[50]{\%} for the chip enable signal.

As stated in Section \ref{subsec:sram}, the memory chips are 16 bits wide, thus data from the processor must be resized from 24 bits to 16 bits before being written to memory.
Similarly, data read from the memory must be resized back to 24 bits before being sent to HDMI.

\subsection{HDMI}
Before the data from memory arrives is used by the HDMI module, it passes through a FIFO queue which has two functions:
\begin{itemize}
    \item Synchronize the data to the clock domain of the HDMI
    \item Act as a buffer in case the memory is too slow
\end{itemize}

That is, we may be able to hide the speed difference between the memory and the HDMI because there is a pause between each frame that the memory can use to catch up with the HDMI data consumption.
To make things worse, the HDMI clocks out a 24 bit pixel on each cycle while the memory only reads 16 bits each cycle.

\section{Convolution Engine}
\label{sec:processor}
In this section we will describe the convolution engine which is at the heart of the FPGA architecture.
We will first describe the convolution engine as a stream processor seen from the outside system before showing the inner workings.

\subsection{The Convolution Engine as a Component}
A design goal for our system was to reconfigure the FPGA depending on the task, which necessitates synthesizing several versions of our architecture so that the correct architecture may be chosen at run time.
In addition to using several architectures, each version is also programmable, allowing the kernel values, map operators and reduce operators to be programmed at runtime.
In order to achieve this we parametrized our design, allowing us to generate different architectures by simply changing a parameter once.
The parameters available are:

\begin{description}
    \item[Kernel Dimensions] \hfill \\
        The most fundamental parameter in our design, the kernel dimension dictates how many pixels we need to calculate a single output pixel.
        This is very fundamental parameter, and we will see how setting the kernel dimension will effect other important sizes in our system as we explore the system.
    \item[Image Input Width] \hfill \\
        The width which input image data is presented 
    \item[Pixel Width] \hfill \\
        The width of each pixel. When image input width and pixel width does not match, for instance with 16 bit input width and 24 bit pixel width, the convolution engine must buffer and translate the input stream 
    \item[Control Input Width] \hfill \\
        As with input data width, the convolution engine must know the width of the incoming control data.
    \item[Image Output Width] \hfill \\
        The data width that the convolution engine should output. As with input, translating widths is necessary.
\end{description}

By parametrizing the convolution engine we can view it as any other processor module with the inputs and outputs shown in Table \ref{tbl:ConvolutionEngineIO}.

\begin{table}[h]
    \begin{tabular}{l | l | l | l }
        &   Signal & Width\\
        \hline
        \multirow{5}{*}{Input}
        &   Image data in           & Image input width     & Data stream from camera on row format
        \\
        &   Image data valid        & 1                     & image data input is valid
        \\
        &   Control data in         & Control data width    & Data stream from MCU
        \\
        &   Control data valid      & 1                     & MCU data is valid
        \\
        &   Request image data      & 1                     & Current output data is received
        \\
        &   Reset                   & 1                     & Convolution engine should reset
        \\\hline
        \multirow{2}{*}{Output}
        &   Image data out          & Image input width     & The processed image data on row format\\
        &   Image data valid        & 1                     & Current output data is valid
    \end{tabular}
    \caption{The interface of the convolution engine, specified by its parameters}
    \label{tbl:ConvolutionEngineIO}
\end{table}

To the outside system the convolution engine is now a module that once programmed operates on a data stream of an image and outputting a processed stream. 
By using valid signals the outside system can provide data at any pace, and throttle the output by requesting data when the convolution engine indicates that data is ready. 

\subsection{Architecture of the convolution engine}

Figure \ref{fig:conv_engine} shows the top level schematic of the convolution engine with the following components:

\begin{description}
    \item[Input buffer] \hfill\\
        The input buffer is a double buffer resonsible for buffering rows of image data and feed it to the processor.
        When a buffer is full it feeds data to the processor as a series of column slices while the other buffer is filled.
    \item[Output buffer] \hfill\\
        The output buffer retrieves data from the processor as a series of column slices and rearranges the output back to row format.
        Figure \ref{fig:sweep_feed} shows how the input buffer feeds the processor with data from a buffered set of rows.
        When data is fed on a column major format within its set of rows we call the data stream a \textit{sweep}, inspired by the way a window is washed by sweeping it with a squeegee.
        The column slices in the sweep are called \textit{sweep slices}.
    \item[Control] \hfill\\
        The control unit is responsible for keeping track of the input and output buffers, waking the processor once an input buffer is ready and making sure the output buffer is empty.
        before a new feeding cycle is started.
        The control unit is also responsible for programming the processor after a reset.
    \item[Processor] \hfill\\
        The heart of the convolution design, where the actual convolution happens
\end{description}

The convolution engine serves two purposes:
\begin{itemize}
    \item Provide a clean interface to the outside system, accepting an image stream and providing an output stream on row major format, tolerating interrupts both ways.
    \item Provide data to the processor as an uninterrupted column major image stream, essentially working as a wrapper for the processor.
\end{itemize}

Having established how the convolution engine provides an interface for the processor, we will now see how the processor works internally.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/convolution_engine.png}
    \caption{The top level schematic of the convolution engine for a 3x3 kernel.}
    \label{fig:conv_engine}
\end{figure}

\subsection{Convolution processor}
This section provides a description of the heart of our architecture.
Figure \ref{fig:convolution_processor} shows the contents of the processor which contains four modules:D
To illustrate how the components work we describe how the first frame of a videostream is processed.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/processor.png}
    \caption{The four main components of the processor.}
    \label{fig:convolution_processor}
\end{figure}

From the outside, the processor is a module working on sweep slices as shown in \ref{fig:sweep_feed}.
A good analogy for how the image is processed is how a window cleaner washes a window.
If we let the dirty window be our original picture, and the clean image be the processed image, the process of convolution is akin to sweeping the squeegee over the window horizontally.
In our analogy, a very small part of the window is under the squeegee at any time.
Similarily, our processor works on a small part of the image at any time, called the \textit{sweep frontier}, shown in \ref{fig:frontier1} and \ref{fig:frontier2}.
To convolute the image the processor consists of the following components:

\begin{description}
    \item[Conveyor] \hfill\\ 
        The conveyor is a special register file consisting of several rows of pixel registers, which holds the pixels currently in the sweep frontier.
        Each row holds a sweep slice, so we should take care to not mix rows in the sense of the entire image, and a rows on the conveyor holding sweep slices which are essentially column slices.
        Following the window washing analogy, the conveyor holds the part of the image right under the squeegee, called the \textit{sweep frontier}
    \item[The Kernel Buffer] \hfill\\
        The kernel buffer maintains the kernel data and must provide the correct kernel data for each map operation performed in the accumulators.
    \item[The accumulator] \hfill\\
To convolute a pixel, we need one mapping unit which maps the neighbourhood of a pixel in sequence, and one reduction unit which performs a reduce operation with the input from its associated mapping unit, and a partially processed pixel.
        Together these two units forms a single accumulation unit, and by employing a row of these units together we can compute several pixels in parallel.
        The accumulator consists of a row of these functional units working on pixels in parallel.
    \item[The Control Unit] \hfill\\
        In order for the accumulators and pixel conveyor to be in sync a control unit sends control signals periodically, which are then propogated throughout the system.
\end{description}

Figure \ref{fig:convolution_processor} shows the insides of the processor. Notice that the conveyor is mirroring the sweep frontier shown in \ref{fig:frontier1}.
We will now explore each part of the processor in greater detail.

\subsubsection{The Conveyor}
The conveyor is tasked with maintaining the sweep frontier, and to feed pixel data to the accumulators.
To maintain the frontier, the conveyor reads input from the convolution engine and writes to the correct slot in the top row.
Recall that the sweep frontier corresponds to column slices, which means data should only be moved directly downwards. Thus a pixel is never moved horizontally, only to the same slot on the column below.
From fig \ref{fig:convolution_processor} we see how each row #########



The accumulator consists of a row of accumulation units, each unit working on one output pixel independant of the other units.
For the 3x3 kernel processor shown in \ref{fig:convolution_processor} we have 7 of these functional units.
To see why, consider that each pixel on the middle row has access to its entire neighbourhood save for the leftmost and righmost pixel, leaving us with 7 full neighbourhoods.
With a 5x5 kernel, we would use a width of 25, leaving us with 21 full neighbourhoods and 21 accumulation units.
There two major concerns for the accumulator unit is:
\begin{itemize}
    \item Mapping the correct pixel with the correct kernel value for every accumulation unit
    \item Make sure every accumulation unit that needs a pixel is ready to recieve it once it is available
\end{itemize}


\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/processor_overview.png}
    \caption{The four core units in the convolution process.}
    \label{fig:processor_core}
\end{figure}

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/daisy_processing.pdf}
    \caption{A full sweep has been buffered, and is being fed to the processor. Meanwhile a new sweep is being buffered}
    \label{fig:sweep_feed}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=10cm]{img/frontier1.png}
    \caption{The frontier. The three rightmost pixels are shown with its full neighbourhood, which overlaps with its neighbours.}
    \label{fig:frontier1}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=10cm]{img/frontier2.png}
    \caption{The image from which the frontier in the previous figure is taken.}
    \label{fig:frontier2}
\end{figure}

\subsubsection{Processing Pixels}
Again, recall from the background section that each output pixel is the result of each neighbour pixel being mapped with its associated kernel and reduced with accumulated value.
With a 3x3 kernel this means we need at least nine cycles per pixel, and with 5x5 we would need 25.
Ideally we want to output a pixel each cycle, which is why we use a row of ALUs, each consisting of a mapping unit and a reduction unit, allowing us to process several pixels simultaneously.
Figure \ref{fig:frontier1} shows how the leftmost and rightmost pixels lack the necessary neighbours, so it makes sense to have as many ALUs as the sweep width, minus the mantle.
For a 5x5 convolution, the mantle would be of size 2, meaning that.

To explain how pixels are processed we will consider a 3x3 kernel.
Each pixel that enters the conveyor is part of 9 neighbourhoods, and should be used in 9 mapping operations.
Ideally the processor should accept one pixel each clock cycle, and conversely it should have a processed pixel ready each cycle, apart from the border pixels which does not have sufficient neighbours.


A natural frontier width, and the one we use, would be as wide as the square of the kernel dimension, 9 in the case of a 3x3 kernel.
To see why this number is special we see what happens if the processor runs optimally.
In this case, running optimally means each pixel is used nine times, and that a new pixel may be accepted every cycle.
By accepting a new pixel in the conveyor every cycle we can now only keep a pixel in its current row for nine cycles, and as long as each pixel is used every cycle a processed pixel should be ready.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/daisy_overview.png}
    \caption{The data path for our processor, named Daisy after the way it daisy chains many control signals.}
    \label{fig:Convolution}
\end{figure}

\begin{description}
    \item[Input Handler] \hfill\\ 
        The interface between the data stream and our processor is responsible for gathering data from a wide variety of input streams of different bandwidths and speeds and present this data to the processor as a continuous data stream with a fixed width.
        In order to do this the input handler must be able to translate from any input width to the desired output width.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/input_handler.png}
    \caption{Illustration of the input handler.}
    \label{fig:Convolution}
\end{figure}

        The processed input is then stored in a double buffer, allowing the input handler to both receive data and feed the processor at the same time.
        As soon as a buffer is filled the input handler indicates that data is available to the processor and outputs data continuously until the buffer is empty.
    \item[Processor] \hfill\\
        The processor receives a pixel stream from the input handler and outputs convoluted data. It consists of a pixel buffer called the conveyor, a buffer for kernel data, an accumulator which performs the map and reduce operations, and a control module. In addition to providing convoluted data it also indicates that the data is valid.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{img/processor.png}
    \caption{Illustration of the processor.}
    \label{fig:Convolution}
\end{figure}

        This is necessary because not all pixels entering the conveyor has access to their full neighbourhood, so the processor cannot provide valid output every cycle.
    \item[Control] \hfill\\
        The control module keeps track of the system state by monitoring the input data stream, and issues control signals according to the state.
        In its initial state the control module is in programming mode. 
        In this state the control module makes sure the initial instructions are dispatched to the correct modules before it enters data mode.
        When in data mode the controller keeps track of the data stream from the input handler, and uses this along with the valid signal from the processor to indicate to the output handler whether the output is valid or not.
    \item[Memory Control] \hfill\\
        Processed data is fed to one of the two SRAM chips serving as frame buffer. The output handler keeps track of which SRAM chip should be written to, and at which address.
\end{description}

\begin{enumerate}

    \item In its initial state the control module is in programming mode. It intercepts data from the input handler and fills the kernel buffer and decodes which map and reduction operation should be used
    \item After the instruction collected the control module enters data mode, and the input module starts filling its double buffer.
    \item When the input module has filled its first buffer it indicates that it is now outputting valid data which the processor will process.
    \item The control module keeps track of how much data has been fed to the processor. When the processor indicates it has valid output the control module signals the memory controller to be ready to write output to SRAM 0.
    \item When the input buffer is exhausted the control waits until all valid data has been flushed from the processor before it resets the processor and waits for the next buffer to fill.
    \item This cycle continues until the memory controller notices it has finished filling SRAM 0 with an entire frame. The memory controller switches to SRAM 1 and prepares for next frame.
\end{enumerate}

\subsection{Input Handler}
% \begin{figure}[h!]
%     \includegraphics[width=\linewidth]{img/Sweeps.png}
%     \caption{The sweep pattern used to collect data for convolution. The deep grey region indicates overlap, pixels which will be collected twice.}
%     \label{fig:Sweeps}
% \end{figure}
% TODO describe how the input handlers work.

% \begin{figure}[h!]
%     \includegraphics[width=\linewidth]{img/FeedPattern.png}
%     \caption{The image three greyed out pixels in the source image represent the three pixels which the regions in grey boxes help calculate. The window is three pixels deep and nine pixels wide.}
%     \label{fig:SweepFrontier}
% \end{figure}

\subsection{Processor}

The processor receives a data stream from the input handler and performs convolution on it, outputting a stream of convoluted image data.
The four main components are:
\begin{description}
    \item[Conveyor] \hfill\\ 
        The conveyor holds data in several rows, each one representing a column slice. The conveyor maintains these rows, moving data from row to row like a conveyor belt, and outputting data from each row to the accumulators.
    \item[The Kernel Buffer] \hfill\\
        The kernel buffer maintains the kernel data and must provide the correct kernel data for each map operation performed in the accumulators.
    \item[The Accumulator] \hfill\\
        The accumulator consists of several buffers, each buffer storing the progress of convolving a pixel.
        Input to the accumulator is data from each row of the conveyor, along with kernel data from the kernel buffer, and it is up to the accumulator to make sure the correct kernel data and pixel data is mapped, and that the result is reduced with the content of the correct accumulator.
    \item[The Control Unit] \hfill\\
        In order for the accumulators and pixel conveyor to be in sync a control unit sends control signals periodically, which are then propagated throughout the system.
\end{description}

% Figure \ref{fig:DaisyView} shows an overview of the four components in the heart of Daisy. 


\subsubsection{The Accumulator}
Although the accumulator unit is the last unit in the data path of Daisy we will cover it first since it helps motivate the designs further up in the chain.
The accumulator actually consists of seven accumulators, hereby referred to as pixel accumulators. Each pixel accumulator corresponds to a pixel in the middle row.
The leftmost and the rightmost pixel in the middle row has no accumulator associated with it because it lacks three pixels necessary for a full convolution, necessetating the slight overlap in our feed pattern.
% In Figure \ref{fig:DaisyView} the input from the conveyor is shown as three wires, one from each row.  
Each accumulator is responsible to read from the correct row at the correct time, such that it accumulates only the subpixels of the source pixel.\\ \\ \\
\\
\begin{tabular}{l*{16}{c}r}
    Time (cycle)        & $T_{0}$ & $T_{1}$ & $T_{2}$ & $T_{2}$ & $T_{4}$  & $T_{5}$ & $T_{6}$ & $T_{7}$ & $T_{8}$ & $T_{9}$ & $T_{10}$ & $T_{11}$ & $T_{12}$ & $T_{13}$ & $T_{14}$\\
\hline
Row 1                   & 4 & 5 & 6 & 7 & 8 & 9 & \cellcolor{gray75} 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4 & 5 & 6 & 7 & 8 & 9 & \\
Row 2                   & 7 & 8 & 9 & \cellcolor{gray75} 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4 & 5 & 6 & 7 & 8 & 9 & \cellcolor{gray75} 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & \\
Row 3                   & \cellcolor{gray75} 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4 & 5 & 6 & 7 & 8 & 9 & \cellcolor{gray75} 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4 & 5 & 6 & \\
\end{tabular}\\ \\ \\
We will first focus on the leftmost accumulator starting at time T0 doing the following reads. 
It first reads three values from Row 3 which corresponds to its south-western sub pixel at $T_{0}$, its southern sub pixel at $T_{1}$, and its south eastern sub pixel at $T_{2}$, shown as the greyed out cells in row 3.
At time $T_{3}$ it starts reading from Row 2, reading its western, middle and eastern sub pixels at respectively $T_{3}$, $T_{4}$, and $T_{5}$, shown as the greyed out cells in row 2.
Finally it reads its north-western, northern and north-western sub pixel at time $T_{6}$ to $T_{8}$ from Row 1.
What about the second leftmost accumulator then? By following the exact same read pattern, but waiting one cycle allows it to read all its values in the same manner as the leftmost accumulator!
The second accumulator reads from Row 3 at time $T_{1}$, switches to Row 2 at $T_{4}$ and again to Row 1 from $T_{7}$ to $T_{9}$. 
In fact, every accumulator starts one cycle later than its left neighbour, meaning every accumulator has accumulated its necessary pixels at different times.
\\ \\
\begin{tabular}{l*{16}{c}r}
    Time (cycle)        & $T_{0}$ & $T_{1}$ & $T_{2}$ & $T_{2}$ & $T_{4}$  & $T_{5}$ & $T_{6}$ & $T_{7}$ & $T_{8}$ & $T_{9}$ & $T_{10}$ & $T_{11}$ & $T_{12}$ & $T_{13}$ & $T_{14}$\\
\hline
Row 1                   & \cellcolor{gray75} 4 & 5 & 6 & 7 & 8 & 9 & 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4\cellcolor{gray75} & 5 & 6 & 7 & 8 & 9 & \\
Row 2                   & 7 & 8 & 9 & 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & \cellcolor{gray75}4 & 5 & 6 & 7 & 8 & 9 & 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & \\
Row 3                   & 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4\cellcolor{gray75} & 5 & 6 & 7 & 8 & 9 & 1 & \cellcolor{gray75} 2 & \cellcolor{gray75} 3 & 4\cellcolor{gray75} & 5 & 6 & \\
\end{tabular}\\ \\ \\

\subsubsection{The Conveyor Belt}
As established last section, the job of the conveyor is to feed data from each of its rows to the accumulator.
In addition to serving data to the accumulator the conveyor must also feed new data to the belt and propogate that data downward which gives rise to its name.
In order to both propagate data downward and feed correct data to the accumulator as efficently as possible the conveyor will utilize the data from a read operation to both feed the accumulator and to transfer data laterally.
When a register is read, it is therefore the job of the register directly beneath it to read, conveying data downwards.
By studying the tables in the previous section we see that reads are done in a wave pattern, and consequentially so is the data conveying, which has a very powerful implication:
Since every accumulator and register will perform the same operation as its left neighbour offset by one cycle we can let each element be responsible for controlling the element to its right.
Rather than using a central control module we can instead simply daisy chain the control signals and interface only with the leftmost components, which also explains the name of the convolution core, Daisy.
An analogy to the read signals is a key. At time $T_{0}$ the control element gives the leftmost register the read key. 
The register does as it is told and reads its new value from the register above, and hands the key over to its neighbour. 
At $T_{1}$ the neighbour recieves the key, and reads from the register above it and sends the key further on.

TODO: Figure out a succint way to explain this part

\subsubsection{The Controller}
We have established how control flows throughout the system, but we still need a module to give out keys to the leftmost accumulators and registers.
The controller is responsible for sending out the keys in the correct order and at the correct time.
Timing is everything, if we misalign read signals and write signals we may end up in a situation where a register fails to read when the register above it writes.
For example, if the controller sends each read signal one cycle too late each register will read when the register to the right side of the one directly above it, causing the data to be sheared as it moves laterally!
Other than issuing read and write keys to the registers, the controller also issues a flush key for the accumulators which tells accumulators to drive DATA\_OUT with its contents, and to reset.

\subsubsection{The Kernel Buffer}
In our schematic we present the kernel buffer as a separate submodule. 
However, having already introduced how instructions are daisy chained it makes sense to do the same with kernels since seven different kernel values are in use at all times.
Thus the kernel values are kept in a shift register queue living as close to the accumulators as possible, needing only two registers to hold the currently unused kernel values.
The responsibilities of the kernel unit is thus to collect the first data values into the kernel buffer chain and to buffer the two kernel values which are not currently in use.
